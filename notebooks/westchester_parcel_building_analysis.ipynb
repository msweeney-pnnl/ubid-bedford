{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1ab4c8d3",
   "metadata": {},
   "source": [
    "# Westchester County Parcel Building Analysis\n",
    "\n",
    "This notebook analyzes Westchester County tax parcels and cross-references them with building databases to determine the number of buildings within each parcel. \n",
    "\n",
    "## Objectives:\n",
    "1. Load and explore parcel data from CSV and shapefile\n",
    "2. Access building footprint databases (Microsoft Buildings, OpenStreetMap)\n",
    "3. Perform spatial analysis to count buildings per parcel\n",
    "4. Create visualizations and export results\n",
    "\n",
    "## Data Sources:\n",
    "- **Parcel Data**: Westchester County tax parcels (CSV + Shapefile)\n",
    "- **Building Data**: Microsoft Building Footprints, OpenStreetMap buildings\n",
    "- **Analysis Period**: Current assessment data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d31a635b",
   "metadata": {},
   "source": [
    "## 1. Import Required Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c803ba1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Core data manipulation and analysis\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Geospatial libraries\n",
    "import geopandas as gpd\n",
    "from shapely.geometry import Point, Polygon\n",
    "import pyproj\n",
    "from pyproj import CRS\n",
    "\n",
    "# Visualization libraries\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import folium\n",
    "from folium import plugins\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "\n",
    "# API access for building data\n",
    "import requests\n",
    "import json\n",
    "import overpy  # For OpenStreetMap data\n",
    "from urllib.parse import urlencode\n",
    "\n",
    "# File handling and OS operations\n",
    "import os\n",
    "import zipfile\n",
    "from pathlib import Path\n",
    "\n",
    "# Statistics and spatial analysis\n",
    "from scipy import stats\n",
    "import contextily as ctx  # For basemaps\n",
    "\n",
    "# Set up plotting style\n",
    "plt.style.use('default')\n",
    "sns.set_palette(\"husl\")\n",
    "\n",
    "print(\"All libraries imported successfully!\")\n",
    "print(f\"Pandas version: {pd.__version__}\")\n",
    "print(f\"GeoPandas version: {gpd.__version__}\")\n",
    "print(f\"NumPy version: {np.__version__}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb7f4c08",
   "metadata": {},
   "source": [
    "## 2. Load Parcel Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d39530c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define data paths\n",
    "DATA_DIR = Path(\"../datasets\")\n",
    "PARCELS_SHP = DATA_DIR / \"Westchester_County_Parcels\" / \"Westchester_Parcels.shp\"\n",
    "PARCELS_CSV = DATA_DIR / \"Westchester_County_Parcels_3053716610941103405.csv\"\n",
    "\n",
    "print(f\"Data directory: {DATA_DIR}\")\n",
    "print(f\"Shapefile exists: {PARCELS_SHP.exists()}\")\n",
    "print(f\"CSV exists: {PARCELS_CSV.exists()}\")\n",
    "\n",
    "# Load the shapefile (preferred for spatial analysis)\n",
    "try:\n",
    "    print(\"\\nLoading shapefile...\")\n",
    "    parcels_gdf = gpd.read_file(PARCELS_SHP)\n",
    "    print(f\"Successfully loaded {len(parcels_gdf):,} parcels from shapefile\")\n",
    "    print(f\"CRS: {parcels_gdf.crs}\")\n",
    "    print(f\"Bounds: {parcels_gdf.total_bounds}\")\n",
    "    \n",
    "    # Display basic info about the shapefile\n",
    "    print(f\"\\nShapefile columns: {list(parcels_gdf.columns)}\")\n",
    "    print(f\"Geometry type: {parcels_gdf.geometry.geom_type.unique()}\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"Error loading shapefile: {e}\")\n",
    "    parcels_gdf = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4d755dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Examine the parcel data structure\n",
    "if parcels_gdf is not None:\n",
    "    print(\"Parcel Data Sample:\")\n",
    "    print(parcels_gdf.head())\n",
    "    \n",
    "    print(f\"\\nData types:\")\n",
    "    print(parcels_gdf.dtypes)\n",
    "    \n",
    "    print(f\"\\nData summary:\")\n",
    "    print(parcels_gdf.describe())\n",
    "    \n",
    "    # Check for missing values\n",
    "    print(f\"\\nMissing values:\")\n",
    "    print(parcels_gdf.isnull().sum())\n",
    "    \n",
    "    # Plot sample parcels\n",
    "    fig, ax = plt.subplots(1, 1, figsize=(12, 8))\n",
    "    \n",
    "    # Plot a sample of parcels (first 1000 for performance)\n",
    "    sample_parcels = parcels_gdf.head(1000)\n",
    "    sample_parcels.plot(ax=ax, alpha=0.7, edgecolor='black', linewidth=0.5)\n",
    "    \n",
    "    plt.title(\"Sample of Westchester County Parcels (First 1000)\")\n",
    "    plt.xlabel(\"Longitude\")\n",
    "    plt.ylabel(\"Latitude\")\n",
    "    plt.grid(True, alpha=0.3)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # Convert to WGS84 for web mapping if needed\n",
    "    if parcels_gdf.crs != 'EPSG:4326':\n",
    "        print(f\"\\nConverting from {parcels_gdf.crs} to WGS84...\")\n",
    "        parcels_wgs84 = parcels_gdf.to_crs('EPSG:4326')\n",
    "        print(\"Conversion complete\")\n",
    "    else:\n",
    "        parcels_wgs84 = parcels_gdf.copy()\n",
    "        \n",
    "    print(f\"\\nWGS84 bounds: {parcels_wgs84.total_bounds}\")\n",
    "    \n",
    "else:\n",
    "    print(\"Shapefile not loaded - cannot proceed with analysis\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0376094",
   "metadata": {},
   "source": [
    "## 3. Load Building/Structure Database\n",
    "\n",
    "We'll access building data from multiple sources:\n",
    "1. **Microsoft Building Footprints** - Comprehensive building polygons\n",
    "2. **OpenStreetMap** - Community-maintained building data\n",
    "3. **Local Building Permits** (if available)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5e14e24",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to download Microsoft Building Footprints for New York\n",
    "def download_microsoft_buildings(bounds):\n",
    "    \"\"\"\n",
    "    Download Microsoft Building Footprints data for a given bounding box\n",
    "    bounds: [minx, miny, maxx, maxy] in WGS84\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Microsoft Building Footprints are available via GitHub releases\n",
    "        # For New York State\n",
    "        url = \"https://usbuildingdata.blob.core.windows.net/usbuildings-v2/NewYork.geojson\"\n",
    "        \n",
    "        print(f\"Downloading Microsoft Building Footprints for New York...\")\n",
    "        print(f\"This may take several minutes due to file size...\")\n",
    "        \n",
    "        # Note: This downloads the entire state - in practice, you might want to \n",
    "        # use a spatial filter or download county-specific data if available\n",
    "        buildings_gdf = gpd.read_file(url, bbox=bounds)\n",
    "        \n",
    "        print(f\"Downloaded {len(buildings_gdf):,} buildings within bounds\")\n",
    "        return buildings_gdf\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error downloading Microsoft buildings: {e}\")\n",
    "        return None\n",
    "\n",
    "# Function to get OpenStreetMap buildings\n",
    "def get_osm_buildings(bounds):\n",
    "    \"\"\"\n",
    "    Get building data from OpenStreetMap using Overpass API\n",
    "    bounds: [minx, miny, maxx, maxy] in WGS84\n",
    "    \"\"\"\n",
    "    try:\n",
    "        api = overpy.Overpass()\n",
    "        \n",
    "        # Construct Overpass query for buildings\n",
    "        query = f\"\"\"\n",
    "        [out:json][timeout:60];\n",
    "        (\n",
    "          way[\"building\"]({bounds[1]},{bounds[0]},{bounds[3]},{bounds[2]});\n",
    "          relation[\"building\"]({bounds[1]},{bounds[0]},{bounds[3]},{bounds[2]});\n",
    "        );\n",
    "        out geom;\n",
    "        \"\"\"\n",
    "        \n",
    "        print(\"Querying OpenStreetMap for buildings...\")\n",
    "        result = api.query(query)\n",
    "        \n",
    "        # Convert to GeoDataFrame\n",
    "        buildings = []\n",
    "        \n",
    "        for way in result.ways:\n",
    "            if len(way.nd) > 2:  # Valid polygon\n",
    "                coords = [(float(node.lon), float(node.lat)) for node in way.nd]\n",
    "                if coords[0] != coords[-1]:  # Close polygon if needed\n",
    "                    coords.append(coords[0])\n",
    "                \n",
    "                if len(coords) >= 4:  # Valid polygon needs at least 4 points\n",
    "                    polygon = Polygon(coords)\n",
    "                    buildings.append({\n",
    "                        'geometry': polygon,\n",
    "                        'osm_id': way.id,\n",
    "                        'building_type': way.tags.get('building', 'yes'),\n",
    "                        'source': 'osm'\n",
    "                    })\n",
    "        \n",
    "        if buildings:\n",
    "            buildings_gdf = gpd.GeoDataFrame(buildings, crs='EPSG:4326')\n",
    "            print(f\"Retrieved {len(buildings_gdf):,} buildings from OpenStreetMap\")\n",
    "            return buildings_gdf\n",
    "        else:\n",
    "            print(\"No buildings found in OpenStreetMap\")\n",
    "            return None\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"Error retrieving OSM buildings: {e}\")\n",
    "        return None\n",
    "\n",
    "print(\"Building data access functions defined successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57329153",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load building data for the parcel area\n",
    "if parcels_wgs84 is not None:\n",
    "    # Get bounding box for the parcel area\n",
    "    bounds = parcels_wgs84.total_bounds  # [minx, miny, maxx, maxy]\n",
    "    print(f\"Study area bounds: {bounds}\")\n",
    "    \n",
    "    # Start with a smaller sample area for testing (optional)\n",
    "    # You can modify this to use the full area\n",
    "    sample_bounds = [\n",
    "        bounds[0], bounds[1],  # SW corner\n",
    "        bounds[0] + (bounds[2] - bounds[0]) * 0.1,  # Reduced area for testing\n",
    "        bounds[1] + (bounds[3] - bounds[1]) * 0.1\n",
    "    ]\n",
    "    \n",
    "    print(f\"Using sample bounds for initial analysis: {sample_bounds}\")\n",
    "    \n",
    "    # Try to get building data from OpenStreetMap first (faster for testing)\n",
    "    print(\"\\n=== Loading OpenStreetMap Buildings ===\")\n",
    "    osm_buildings = get_osm_buildings(sample_bounds)\n",
    "    \n",
    "    # Optionally load Microsoft Building Footprints\n",
    "    # Uncomment the following lines if you want to use Microsoft data\n",
    "    # WARNING: This will download a large file (entire NY state)\n",
    "    \n",
    "    print(\"\\n=== Loading Microsoft Building Footprints ===\")\n",
    "    print(\"Note: This downloads the entire NY state dataset - may take time\")\n",
    "    choice = input(\"Download Microsoft Buildings? (y/n): \").lower()\n",
    "    \n",
    "    if choice == 'y':\n",
    "        ms_buildings = download_microsoft_buildings(bounds)\n",
    "    else:\n",
    "        print(\"Skipping Microsoft Buildings download\")\n",
    "        ms_buildings = None\n",
    "        \n",
    "else:\n",
    "    print(\"No parcel data available - cannot proceed with building data retrieval\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8dd9a26",
   "metadata": {},
   "source": [
    "## 4. Data Exploration and Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "318f8a6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine and preprocess building data\n",
    "buildings_list = []\n",
    "\n",
    "if osm_buildings is not None:\n",
    "    osm_buildings['source'] = 'OpenStreetMap'\n",
    "    buildings_list.append(osm_buildings)\n",
    "    print(f\"OSM Buildings: {len(osm_buildings):,}\")\n",
    "\n",
    "if 'ms_buildings' in locals() and ms_buildings is not None:\n",
    "    ms_buildings['source'] = 'Microsoft'\n",
    "    ms_buildings['building_type'] = 'building'  # Standardize column\n",
    "    buildings_list.append(ms_buildings)\n",
    "    print(f\"Microsoft Buildings: {len(ms_buildings):,}\")\n",
    "\n",
    "# Combine all building sources\n",
    "if buildings_list:\n",
    "    # Find common columns\n",
    "    common_cols = ['geometry', 'source']\n",
    "    \n",
    "    # Add building_type if it exists in all datasets\n",
    "    if all('building_type' in df.columns for df in buildings_list):\n",
    "        common_cols.append('building_type')\n",
    "    \n",
    "    # Standardize datasets to common columns\n",
    "    standardized_buildings = []\n",
    "    for df in buildings_list:\n",
    "        df_std = df[common_cols].copy()\n",
    "        standardized_buildings.append(df_std)\n",
    "    \n",
    "    # Combine all building data\n",
    "    buildings_combined = gpd.GeoDataFrame(\n",
    "        pd.concat(standardized_buildings, ignore_index=True),\n",
    "        crs='EPSG:4326'\n",
    "    )\n",
    "    \n",
    "    print(f\"\\nCombined Buildings Dataset:\")\n",
    "    print(f\"Total buildings: {len(buildings_combined):,}\")\n",
    "    print(f\"Sources: {buildings_combined['source'].value_counts().to_dict()}\")\n",
    "    \n",
    "    # Remove any invalid geometries\n",
    "    buildings_combined = buildings_combined[buildings_combined.geometry.is_valid]\n",
    "    print(f\"Valid buildings: {len(buildings_combined):,}\")\n",
    "    \n",
    "    # Convert to same CRS as parcels for spatial operations\n",
    "    if parcels_gdf is not None:\n",
    "        buildings_combined = buildings_combined.to_crs(parcels_gdf.crs)\n",
    "        print(f\"Converted buildings to CRS: {buildings_combined.crs}\")\n",
    "        \n",
    "else:\n",
    "    print(\"No building data available for analysis\")\n",
    "    buildings_combined = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dddd4fe8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize the data overlap\n",
    "if parcels_gdf is not None and buildings_combined is not None:\n",
    "    \n",
    "    # Create a sample for visualization (performance)\n",
    "    sample_parcels = parcels_gdf.head(100)\n",
    "    \n",
    "    # Filter buildings to sample area\n",
    "    sample_bounds_proj = sample_parcels.total_bounds\n",
    "    buildings_sample = buildings_combined.cx[\n",
    "        sample_bounds_proj[0]:sample_bounds_proj[2],\n",
    "        sample_bounds_proj[1]:sample_bounds_proj[3]\n",
    "    ]\n",
    "    \n",
    "    # Create visualization\n",
    "    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(16, 8))\n",
    "    \n",
    "    # Plot 1: Parcels only\n",
    "    sample_parcels.plot(ax=ax1, alpha=0.7, edgecolor='blue', facecolor='lightblue')\n",
    "    ax1.set_title(f\"Sample Parcels (n={len(sample_parcels)})\")\n",
    "    ax1.set_xlabel(\"X Coordinate\")\n",
    "    ax1.set_ylabel(\"Y Coordinate\")\n",
    "    \n",
    "    # Plot 2: Parcels with buildings\n",
    "    sample_parcels.plot(ax=ax2, alpha=0.5, edgecolor='blue', facecolor='lightblue', linewidth=0.5)\n",
    "    \n",
    "    if len(buildings_sample) > 0:\n",
    "        buildings_sample.plot(ax=ax2, color='red', alpha=0.8, markersize=1)\n",
    "        ax2.set_title(f\"Parcels + Buildings (n={len(buildings_sample)} buildings)\")\n",
    "    else:\n",
    "        ax2.set_title(\"Parcels (No buildings in sample area)\")\n",
    "    \n",
    "    ax2.set_xlabel(\"X Coordinate\")\n",
    "    ax2.set_ylabel(\"Y Coordinate\")\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    print(f\"Sample area contains {len(buildings_sample):,} buildings\")\n",
    "    \n",
    "else:\n",
    "    print(\"Cannot create visualization - missing parcel or building data\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b83ef36",
   "metadata": {},
   "source": [
    "## 5. Spatial Join Operations\n",
    "\n",
    "Perform spatial joins to determine which buildings fall within each parcel boundary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6a4ed9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to perform spatial join and count buildings per parcel\n",
    "def count_buildings_per_parcel(parcels_gdf, buildings_gdf, sample_size=None):\n",
    "    \"\"\"\n",
    "    Count buildings within each parcel using spatial join\n",
    "    \n",
    "    Parameters:\n",
    "    parcels_gdf: GeoDataFrame of parcels\n",
    "    buildings_gdf: GeoDataFrame of buildings\n",
    "    sample_size: Number of parcels to analyze (None for all)\n",
    "    \n",
    "    Returns:\n",
    "    GeoDataFrame with building counts per parcel\n",
    "    \"\"\"\n",
    "    \n",
    "    if sample_size:\n",
    "        parcels_sample = parcels_gdf.head(sample_size).copy()\n",
    "        print(f\"Analyzing sample of {len(parcels_sample):,} parcels\")\n",
    "    else:\n",
    "        parcels_sample = parcels_gdf.copy()\n",
    "        print(f\"Analyzing all {len(parcels_sample):,} parcels\")\n",
    "    \n",
    "    # Ensure both datasets have the same CRS\n",
    "    if parcels_sample.crs != buildings_gdf.crs:\n",
    "        buildings_gdf = buildings_gdf.to_crs(parcels_sample.crs)\n",
    "        print(f\"Converted buildings to CRS: {buildings_gdf.crs}\")\n",
    "    \n",
    "    # Add unique parcel ID if not present\n",
    "    if 'parcel_id' not in parcels_sample.columns:\n",
    "        parcels_sample['parcel_id'] = parcels_sample.index\n",
    "    \n",
    "    print(\"Performing spatial join...\")\n",
    "    \n",
    "    # Method 1: Using spatial join (recommended for point buildings)\n",
    "    # For building polygons, we'll use centroid to convert to points\n",
    "    if 'Point' not in buildings_gdf.geometry.geom_type.unique():\n",
    "        print(\"Converting building polygons to centroids...\")\n",
    "        buildings_points = buildings_gdf.copy()\n",
    "        buildings_points.geometry = buildings_gdf.geometry.centroid\n",
    "    else:\n",
    "        buildings_points = buildings_gdf.copy()\n",
    "    \n",
    "    # Perform spatial join\n",
    "    buildings_with_parcels = gpd.sjoin(\n",
    "        buildings_points, \n",
    "        parcels_sample[['parcel_id', 'geometry']], \n",
    "        how='inner', \n",
    "        predicate='within'\n",
    "    )\n",
    "    \n",
    "    print(f\"Found {len(buildings_with_parcels):,} buildings within parcels\")\n",
    "    \n",
    "    # Count buildings per parcel\n",
    "    building_counts = buildings_with_parcels.groupby('parcel_id').size().reset_index(name='building_count')\n",
    "    \n",
    "    # Merge back with parcels\n",
    "    parcels_with_counts = parcels_sample.merge(\n",
    "        building_counts, \n",
    "        on='parcel_id', \n",
    "        how='left'\n",
    "    )\n",
    "    \n",
    "    # Fill NaN values with 0 (parcels with no buildings)\n",
    "    parcels_with_counts['building_count'] = parcels_with_counts['building_count'].fillna(0).astype(int)\n",
    "    \n",
    "    return parcels_with_counts, buildings_with_parcels\n",
    "\n",
    "# Execute the spatial analysis\n",
    "if parcels_gdf is not None and buildings_combined is not None:\n",
    "    print(\"=== Starting Spatial Analysis ===\")\n",
    "    \n",
    "    # Start with a sample for testing (remove sample_size=1000 to analyze all parcels)\n",
    "    parcels_with_counts, buildings_with_parcels = count_buildings_per_parcel(\n",
    "        parcels_gdf, \n",
    "        buildings_combined, \n",
    "        sample_size=1000  # Remove this parameter to analyze all parcels\n",
    "    )\n",
    "    \n",
    "    print(f\"\\\\nAnalysis Complete!\")\n",
    "    print(f\"Parcels analyzed: {len(parcels_with_counts):,}\")\n",
    "    print(f\"Parcels with buildings: {(parcels_with_counts['building_count'] > 0).sum():,}\")\n",
    "    print(f\"Total buildings found: {parcels_with_counts['building_count'].sum():,}\")\n",
    "    \n",
    "else:\n",
    "    print(\"Cannot perform spatial analysis - missing data\")\n",
    "    parcels_with_counts = None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75023dd1",
   "metadata": {},
   "source": [
    "## 6. Count Buildings per Parcel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c99c689c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Detailed analysis of building counts\n",
    "if parcels_with_counts is not None:\n",
    "    \n",
    "    print(\"=== Building Count Analysis ===\")\n",
    "    \n",
    "    # Basic statistics\n",
    "    building_stats = parcels_with_counts['building_count'].describe()\n",
    "    print(\"Building Count Statistics:\")\n",
    "    print(building_stats)\n",
    "    \n",
    "    # Distribution analysis\n",
    "    count_distribution = parcels_with_counts['building_count'].value_counts().sort_index()\n",
    "    print(f\"\\\\nBuilding Count Distribution (Top 10):\")\n",
    "    print(count_distribution.head(10))\n",
    "    \n",
    "    # Parcels with unusual building counts\n",
    "    high_building_parcels = parcels_with_counts[parcels_with_counts['building_count'] >= 10]\n",
    "    print(f\"\\\\nParcels with 10+ buildings: {len(high_building_parcels):,}\")\n",
    "    \n",
    "    if len(high_building_parcels) > 0:\n",
    "        print(\"Top 5 parcels by building count:\")\n",
    "        top_parcels = high_building_parcels.nlargest(5, 'building_count')\n",
    "        for idx, row in top_parcels.iterrows():\n",
    "            print(f\"  Parcel {row['parcel_id']}: {row['building_count']} buildings\")\n",
    "    \n",
    "    # Zero building analysis\n",
    "    zero_building_parcels = parcels_with_counts[parcels_with_counts['building_count'] == 0]\n",
    "    print(f\"\\\\nParcels with no buildings: {len(zero_building_parcels):,}\")\n",
    "    print(f\"Percentage with no buildings: {len(zero_building_parcels)/len(parcels_with_counts)*100:.1f}%\")\n",
    "    \n",
    "    # Create summary table\n",
    "    summary_table = pd.DataFrame({\n",
    "        'Category': [\n",
    "            'Total Parcels',\n",
    "            'Parcels with Buildings',\n",
    "            'Parcels without Buildings', \n",
    "            'Total Buildings Found',\n",
    "            'Average Buildings per Parcel',\n",
    "            'Max Buildings in Single Parcel'\n",
    "        ],\n",
    "        'Count': [\n",
    "            len(parcels_with_counts),\n",
    "            (parcels_with_counts['building_count'] > 0).sum(),\n",
    "            (parcels_with_counts['building_count'] == 0).sum(),\n",
    "            parcels_with_counts['building_count'].sum(),\n",
    "            round(parcels_with_counts['building_count'].mean(), 2),\n",
    "            parcels_with_counts['building_count'].max()\n",
    "        ]\n",
    "    })\n",
    "    \n",
    "    print(\"\\\\n=== Summary Table ===\")\n",
    "    print(summary_table.to_string(index=False))\n",
    "    \n",
    "else:\n",
    "    print(\"No building count data available for analysis\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f13db1ec",
   "metadata": {},
   "source": [
    "## 7. Statistical Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcaf7772",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Advanced statistical analysis\n",
    "if parcels_with_counts is not None:\n",
    "    \n",
    "    # Calculate parcel areas if available\n",
    "    parcels_with_counts['area_sq_m'] = parcels_with_counts.geometry.area\n",
    "    parcels_with_counts['area_acres'] = parcels_with_counts['area_sq_m'] / 4047  # Convert to acres\n",
    "    \n",
    "    # Building density (buildings per acre)\n",
    "    parcels_with_counts['building_density'] = parcels_with_counts['building_count'] / parcels_with_counts['area_acres']\n",
    "    parcels_with_counts['building_density'] = parcels_with_counts['building_density'].replace([np.inf, -np.inf], 0)\n",
    "    \n",
    "    print(\"=== Statistical Analysis ===\")\n",
    "    \n",
    "    # Correlation analysis\n",
    "    if 'area_acres' in parcels_with_counts.columns:\n",
    "        correlation = parcels_with_counts['building_count'].corr(parcels_with_counts['area_acres'])\n",
    "        print(f\"Correlation between parcel area and building count: {correlation:.3f}\")\n",
    "    \n",
    "    # Building density statistics\n",
    "    density_stats = parcels_with_counts['building_density'].describe()\n",
    "    print(\"\\\\nBuilding Density Statistics (buildings per acre):\")\n",
    "    print(density_stats)\n",
    "    \n",
    "    # Identify outliers (parcels with unusually high building density)\n",
    "    q75 = parcels_with_counts['building_density'].quantile(0.75)\n",
    "    q25 = parcels_with_counts['building_density'].quantile(0.25)\n",
    "    iqr = q75 - q25\n",
    "    outlier_threshold = q75 + 1.5 * iqr\n",
    "    \n",
    "    outliers = parcels_with_counts[parcels_with_counts['building_density'] > outlier_threshold]\n",
    "    print(f\"\\\\nOutliers (high density parcels): {len(outliers):,}\")\n",
    "    \n",
    "    if len(outliers) > 0:\n",
    "        print(\"Top 5 highest density parcels:\")\n",
    "        top_density = outliers.nlargest(5, 'building_density')\n",
    "        for idx, row in top_density.iterrows():\n",
    "            print(f\"  Parcel {row['parcel_id']}: {row['building_count']} buildings, \"\n",
    "                  f\"{row['area_acres']:.2f} acres, {row['building_density']:.2f} buildings/acre\")\n",
    "    \n",
    "    # Distribution by building count categories\n",
    "    def categorize_building_count(count):\n",
    "        if count == 0:\n",
    "            return 'No Buildings'\n",
    "        elif count == 1:\n",
    "            return 'Single Building'\n",
    "        elif count <= 5:\n",
    "            return '2-5 Buildings'\n",
    "        elif count <= 10:\n",
    "            return '6-10 Buildings'\n",
    "        else:\n",
    "            return '11+ Buildings'\n",
    "    \n",
    "    parcels_with_counts['building_category'] = parcels_with_counts['building_count'].apply(categorize_building_count)\n",
    "    \n",
    "    category_counts = parcels_with_counts['building_category'].value_counts()\n",
    "    category_percentages = parcels_with_counts['building_category'].value_counts(normalize=True) * 100\n",
    "    \n",
    "    print(\"\\\\n=== Building Count Categories ===\")\n",
    "    for category in category_counts.index:\n",
    "        print(f\"{category}: {category_counts[category]:,} parcels ({category_percentages[category]:.1f}%)\")\n",
    "        \n",
    "else:\n",
    "    print(\"No data available for statistical analysis\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "187dc615",
   "metadata": {},
   "source": [
    "## 8. Visualization of Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac82e0f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create comprehensive visualizations\n",
    "if parcels_with_counts is not None:\n",
    "    \n",
    "    # Set up the plotting style\n",
    "    plt.style.use('default')\n",
    "    \n",
    "    # 1. Histogram of building counts\n",
    "    fig, ((ax1, ax2), (ax3, ax4)) = plt.subplots(2, 2, figsize=(16, 12))\n",
    "    \n",
    "    # Building count distribution\n",
    "    parcels_with_counts['building_count'].hist(bins=50, ax=ax1, alpha=0.7, color='skyblue', edgecolor='black')\n",
    "    ax1.set_xlabel('Number of Buildings')\n",
    "    ax1.set_ylabel('Number of Parcels')\n",
    "    ax1.set_title('Distribution of Building Counts per Parcel')\n",
    "    ax1.grid(True, alpha=0.3)\n",
    "    \n",
    "    # Building density distribution\n",
    "    parcels_with_counts['building_density'].hist(bins=50, ax=ax2, alpha=0.7, color='lightgreen', edgecolor='black')\n",
    "    ax2.set_xlabel('Building Density (buildings/acre)')\n",
    "    ax2.set_ylabel('Number of Parcels')\n",
    "    ax2.set_title('Distribution of Building Density')\n",
    "    ax2.grid(True, alpha=0.3)\n",
    "    \n",
    "    # Parcel area vs building count scatter\n",
    "    ax3.scatter(parcels_with_counts['area_acres'], parcels_with_counts['building_count'], \n",
    "               alpha=0.6, s=20, color='coral')\n",
    "    ax3.set_xlabel('Parcel Area (acres)')\n",
    "    ax3.set_ylabel('Number of Buildings')\n",
    "    ax3.set_title('Parcel Area vs Building Count')\n",
    "    ax3.grid(True, alpha=0.3)\n",
    "    \n",
    "    # Building categories pie chart\n",
    "    category_counts = parcels_with_counts['building_category'].value_counts()\n",
    "    ax4.pie(category_counts.values, labels=category_counts.index, autopct='%1.1f%%', startangle=90)\n",
    "    ax4.set_title('Distribution of Parcel Building Categories')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # 2. Box plot analysis\n",
    "    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(14, 6))\n",
    "    \n",
    "    # Box plot of building counts by category\n",
    "    category_order = ['No Buildings', 'Single Building', '2-5 Buildings', '6-10 Buildings', '11+ Buildings']\n",
    "    existing_categories = [cat for cat in category_order if cat in parcels_with_counts['building_category'].unique()]\n",
    "    \n",
    "    sns.boxplot(data=parcels_with_counts, x='building_category', y='area_acres', \n",
    "                order=existing_categories, ax=ax1)\n",
    "    ax1.set_xticklabels(ax1.get_xticklabels(), rotation=45)\n",
    "    ax1.set_title('Parcel Area by Building Category')\n",
    "    ax1.set_ylabel('Area (acres)')\n",
    "    \n",
    "    # Violin plot of building density\n",
    "    non_zero_density = parcels_with_counts[parcels_with_counts['building_density'] > 0]\n",
    "    if len(non_zero_density) > 0:\n",
    "        sns.violinplot(data=non_zero_density, y='building_density', ax=ax2)\n",
    "        ax2.set_title('Building Density Distribution\\\\n(Parcels with Buildings Only)')\n",
    "        ax2.set_ylabel('Building Density (buildings/acre)')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "else:\n",
    "    print(\"No data available for visualization\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f622be45",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create choropleth map showing building density\n",
    "if parcels_with_counts is not None:\n",
    "    \n",
    "    # Convert to WGS84 for web mapping\n",
    "    parcels_wgs84_counts = parcels_with_counts.to_crs('EPSG:4326')\n",
    "    \n",
    "    # Create color scheme based on building count\n",
    "    def get_color(building_count):\n",
    "        if building_count == 0:\n",
    "            return 'lightgray'\n",
    "        elif building_count == 1:\n",
    "            return 'lightblue'\n",
    "        elif building_count <= 5:\n",
    "            return 'yellow'\n",
    "        elif building_count <= 10:\n",
    "            return 'orange'\n",
    "        else:\n",
    "            return 'red'\n",
    "    \n",
    "    parcels_wgs84_counts['color'] = parcels_wgs84_counts['building_count'].apply(get_color)\n",
    "    \n",
    "    # Create an interactive map\n",
    "    center_lat = parcels_wgs84_counts.geometry.centroid.y.mean()\n",
    "    center_lon = parcels_wgs84_counts.geometry.centroid.x.mean()\n",
    "    \n",
    "    # Create base map\n",
    "    m = folium.Map(\n",
    "        location=[center_lat, center_lon],\n",
    "        zoom_start=12,\n",
    "        tiles='OpenStreetMap'\n",
    "    )\n",
    "    \n",
    "    # Add parcels to map (sample for performance)\n",
    "    sample_for_map = parcels_wgs84_counts.head(200)  # Adjust sample size as needed\n",
    "    \n",
    "    for idx, row in sample_for_map.iterrows():\n",
    "        # Create popup text\n",
    "        popup_text = f\"\"\"\n",
    "        <b>Parcel ID:</b> {row['parcel_id']}<br>\n",
    "        <b>Buildings:</b> {row['building_count']}<br>\n",
    "        <b>Area:</b> {row['area_acres']:.2f} acres<br>\n",
    "        <b>Density:</b> {row['building_density']:.2f} buildings/acre\n",
    "        \"\"\"\n",
    "        \n",
    "        # Add parcel polygon\n",
    "        folium.GeoJson(\n",
    "            row.geometry,\n",
    "            style_function=lambda x, color=row['color']: {\n",
    "                'fillColor': color,\n",
    "                'color': 'black',\n",
    "                'weight': 1,\n",
    "                'fillOpacity': 0.7\n",
    "            },\n",
    "            popup=folium.Popup(popup_text, max_width=300)\n",
    "        ).add_to(m)\n",
    "    \n",
    "    # Add legend\n",
    "    legend_html = '''\n",
    "    <div style=\"position: fixed; \n",
    "                top: 10px; right: 10px; width: 180px; height: 120px; \n",
    "                background-color: white; border:2px solid grey; z-index:9999; \n",
    "                font-size:14px; padding: 10px\n",
    "                \">\n",
    "    <b>Building Count Legend</b><br>\n",
    "    <i class=\"fa fa-square\" style=\"color:lightgray\"></i> 0 Buildings<br>\n",
    "    <i class=\"fa fa-square\" style=\"color:lightblue\"></i> 1 Building<br>\n",
    "    <i class=\"fa fa-square\" style=\"color:yellow\"></i> 2-5 Buildings<br>\n",
    "    <i class=\"fa fa-square\" style=\"color:orange\"></i> 6-10 Buildings<br>\n",
    "    <i class=\"fa fa-square\" style=\"color:red\"></i> 11+ Buildings<br>\n",
    "    </div>\n",
    "    '''\n",
    "    m.get_root().html.add_child(folium.Element(legend_html))\n",
    "    # Save the map\n",
    "    map_file = \"../results/westchester_parcel_buildings_map.html\"\n",
    "    os.makedirs(os.path.dirname(map_file), exist_ok=True)\n",
    "    m.save(map_file)\n",
    "    print(f\"Interactive map saved to: {map_file}\")\n",
    "    \n",
    "    # Display map in notebook (if running in Jupyter)\n",
    "    display(m)\n",
    "    \n",
    "else:\n",
    "    print(\"No data available for mapping\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe2b026c",
   "metadata": {},
   "source": [
    "## 9. Export Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ad7f04c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export results to various formats\n",
    "if parcels_with_counts is not None:\n",
    "    \n",
    "    # Create results directory\n",
    "    results_dir = Path(\"../results\")\n",
    "    results_dir.mkdir(exist_ok=True)\n",
    "    \n",
    "    print(\"=== Exporting Results ===\")\n",
    "    \n",
    "    # 1. Export to CSV (tabular data)\n",
    "    csv_file = results_dir / \"westchester_parcels_with_building_counts.csv\"\n",
    "    \n",
    "    # Prepare data for CSV export (remove geometry for smaller file)\n",
    "    export_df = parcels_with_counts.drop('geometry', axis=1)\n",
    "    export_df.to_csv(csv_file, index=False)\n",
    "    print(f\"CSV exported to: {csv_file}\")\n",
    "    \n",
    "    # 2. Export to Shapefile (spatial data)\n",
    "    shp_file = results_dir / \"westchester_parcels_with_building_counts.shp\"\n",
    "    parcels_with_counts.to_file(shp_file, driver='ESRI Shapefile')\n",
    "    print(f\"Shapefile exported to: {shp_file}\")\n",
    "    \n",
    "    # 3. Export to GeoJSON (web-friendly format)\n",
    "    geojson_file = results_dir / \"westchester_parcels_with_building_counts.geojson\"\n",
    "    parcels_with_counts.to_file(geojson_file, driver='GeoJSON')\n",
    "    print(f\"GeoJSON exported to: {geojson_file}\")\n",
    "    \n",
    "    # 4. Export summary statistics\n",
    "    summary_file = results_dir / \"building_count_summary.txt\"\n",
    "    \n",
    "    with open(summary_file, 'w') as f:\n",
    "        f.write(\"Westchester County Parcel Building Analysis Summary\\\\n\")\n",
    "        f.write(\"=\" * 50 + \"\\\\n\\\\n\")\n",
    "        f.write(f\"Analysis Date: {pd.Timestamp.now().strftime('%Y-%m-%d %H:%M:%S')}\\\\n\\\\n\")\n",
    "        f.write(f\"Total Parcels Analyzed: {len(parcels_with_counts):,}\\\\n\")\n",
    "        f.write(f\"Parcels with Buildings: {(parcels_with_counts['building_count'] > 0).sum():,}\\\\n\")\n",
    "        f.write(f\"Parcels without Buildings: {(parcels_with_counts['building_count'] == 0).sum():,}\\\\n\")\n",
    "        f.write(f\"Total Buildings Found: {parcels_with_counts['building_count'].sum():,}\\\\n\")\n",
    "        f.write(f\"Average Buildings per Parcel: {parcels_with_counts['building_count'].mean():.2f}\\\\n\")\n",
    "        f.write(f\"Maximum Buildings in Single Parcel: {parcels_with_counts['building_count'].max()}\\\\n\\\\n\")\n",
    "        \n",
    "        f.write(\"Building Count Distribution:\\\\n\")\n",
    "        category_counts = parcels_with_counts['building_category'].value_counts()\n",
    "        for category, count in category_counts.items():\n",
    "            percentage = count / len(parcels_with_counts) * 100\n",
    "            f.write(f\"  {category}: {count:,} parcels ({percentage:.1f}%)\\\\n\")\n",
    "    \n",
    "    print(f\"Summary report exported to: {summary_file}\")\n",
    "    \n",
    "    # 5. Export building data if available\n",
    "    if 'buildings_with_parcels' in locals() and buildings_with_parcels is not None:\n",
    "        buildings_csv = results_dir / \"buildings_within_parcels.csv\"\n",
    "        buildings_export = buildings_with_parcels.drop('geometry', axis=1)\n",
    "        buildings_export.to_csv(buildings_csv, index=False)\n",
    "        print(f\"Buildings data exported to: {buildings_csv}\")\n",
    "    \n",
    "    print(f\"\\\\nAll results exported to: {results_dir.absolute()}\")\n",
    "    \n",
    "    # Create a final summary\n",
    "    print(\"\\\\n\" + \"=\" * 60)\n",
    "    print(\"ANALYSIS COMPLETE\")\n",
    "    print(\"=\" * 60)\n",
    "    print(f\"✓ Analyzed {len(parcels_with_counts):,} parcels\")\n",
    "    print(f\"✓ Found {parcels_with_counts['building_count'].sum():,} buildings\")\n",
    "    print(f\"✓ {(parcels_with_counts['building_count'] > 0).sum():,} parcels contain buildings\")\n",
    "    print(f\"✓ Results exported to {results_dir.absolute()}\")\n",
    "    print(\"✓ Interactive map created\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "else:\n",
    "    print(\"No results to export - analysis was not completed\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0121fcc0",
   "metadata": {},
   "source": [
    "## Next Steps and Recommendations\n",
    "\n",
    "### Potential Improvements:\n",
    "1. **Enhanced Building Data Sources**:\n",
    "   - Access local building permit databases\n",
    "   - Use LiDAR data for 3D building detection\n",
    "   - Incorporate real estate datasets\n",
    "\n",
    "2. **Advanced Analysis**:\n",
    "   - Building height estimation\n",
    "   - Land use classification\n",
    "   - Property value correlation\n",
    "   - Temporal analysis of building construction\n",
    "\n",
    "3. **Performance Optimization**:\n",
    "   - Use spatial indexing for large datasets\n",
    "   - Implement parallel processing\n",
    "   - Consider cloud computing for state-wide analysis\n",
    "\n",
    "4. **Data Quality Improvements**:\n",
    "   - Validate building footprints against aerial imagery\n",
    "   - Cross-reference multiple building databases\n",
    "   - Implement confidence scoring\n",
    "\n",
    "### Usage Notes:\n",
    "- This analysis used a sample of data for performance\n",
    "- Remove sample size limitations for full county analysis\n",
    "- Building data accuracy varies by source and location\n",
    "- Results should be validated against ground truth data\n",
    "\n",
    "### Contact Information:\n",
    "For questions about this analysis, please refer to the data sources and methodology documentation."
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
